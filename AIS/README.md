# ü§∞ Assistente Virtual de Aconselhamento Pr√©-Natal (IA)

**Unidade Curricular:** Ambientes Inteligentes para a Sa√∫de (AIS)

**Mestrado em Engenharia Biom√©dica | Inform√°tica M√©dica**

**Universidade do Minho** - 2024/2025

Este reposit√≥rio cont√©m a documenta√ß√£o e an√°lise do desenvolvimento de um **assistente virtual baseado em LLMs (Large Language Models)**, desenhado para prestar esclarecimentos e apoio durante a gravidez. O projeto utiliza a framework **Ollama** para comparar o desempenho de diferentes modelos na resposta a quest√µes sobre desenvolvimento fetal, nutri√ß√£o e cuidados pr√©-natais.

## üìÑ Sobre o Projeto

A gravidez √© uma fase marcada por d√∫vidas e ansiedade. O objetivo deste trabalho foi criar um assistente capaz de fornecer informa√ß√µes r√°pidas, acess√≠veis e fundamentadas, complementando (sem substituir) o acompanhamento m√©dico tradicional.

O foco principal foi o **Fine-Tuning de par√¢metros** (via Modelfile) e a **Engenharia de Prompt** para garantir que o assistente fosse n√£o s√≥ preciso clinicamente, mas tamb√©m emp√°tico e seguro.

## üéØ Objetivos

* **Desenvolver** um assistente virtual focado no contexto cl√≠nico pr√©-natal.
* **Comparar** o comportamento de diferentes LLMs (pequena e m√©dia escala).
* **Otimizar** as respostas ajustando par√¢metros como `temperature`, `top_k` e `seed`.
* **Avaliar** a precis√£o cl√≠nica, clareza e empatia das respostas geradas.

## üõ†Ô∏è Tecnologias Utilizadas

* **Framework:** [Ollama](https://ollama.com/) (Execu√ß√£o local de LLMs).
* **Interface:** [Open WebUI](https://docs.openwebui.com/) (Intera√ß√£o gr√°fica com os modelos).
* **Engenharia de Prompt:** Defini√ß√£o de *System Prompts* espec√≠ficos para criar uma persona "emp√°tica e baseada em evid√™ncias".

## ü§ñ Modelos Avaliados

Foram testados quatro modelos distintos, escolhidos pelo equil√≠brio entre desempenho e efici√™ncia computacional:

1. **Phi3 (3.8B):** Modelo leve, focado em efici√™ncia.
2. **LLaMA 3.2 (3B):** Modelo da Meta otimizado para instru√ß√µes.
3. **Gemma-3 (4B):** Modelo aberto da Google.
4. **Mistral (7B):** Modelo conhecido pela fluidez comunicativa.

> 
> **Nota:** Modelos maiores (como LLaMA 3.1 8B) foram exclu√≠dos devido a limita√ß√µes de recursos computacionais.
> 
> 

## ‚öôÔ∏è Configura√ß√£o e Par√¢metros

A personaliza√ß√£o foi feita atrav√©s do **Modelfile** do Ollama, ajustando as seguintes vari√°veis para controlar a criatividade e consist√™ncia:

* **Temperature:** Variou entre 0.3 e 0.5 (Controlo de aleatoriedade).
* **Top_k:** Variou entre 30 e 45 (Sele√ß√£o de tokens prov√°veis).
* **Seed:** Fixada em 35 para reprodutibilidade.
* **System Prompt:** Instru√ß√µes estritas para manter um tom emp√°tico, evitar diagn√≥sticos m√©dicos e n√£o usar adjetivos subjetivos exagerados (ex: "wonderful", "amazing").

## üìä Resultados e Conclus√µes

Os modelos foram submetidos a um conjunto de 8 perguntas-chave e 3 cen√°rios cl√≠nicos complexos.

| Modelo | Avalia√ß√£o Geral |
| --- | --- |
| **Phi3** | **Fraco.** Apresentou v√°rias imprecis√µes t√©cnicas (alucina√ß√µes sobre marcos gestacionais). |
| **LLaMA** | **M√©dio.** Boa estrutura, mas propenso a erros graves com temperaturas mais altas (ex: sugeriu alimentos inseguros). |
| **Mistral** | **Bom.** Excelente capacidade comunicativa e educativa, mas por vezes superficial tecnicamente. |
| **Gemma** | **Excelente (Vencedor).** Foi o modelo mais equilibrado. Combinou rigor t√©cnico, clareza e o n√≠vel certo de empatia ("Your little one"). |

**Conclus√£o Principal:**
O modelo **Gemma** destacou-se como a melhor op√ß√£o para este dom√≠nio. Contudo, o trabalho evidenciou que LLMs gen√©ricos, sem acesso a bases de conhecimento externas (RAG), t√™m limita√ß√µes em casos cl√≠nicos complexos e necessitam de supervis√£o humana.

## üîÆ Trabalho Futuro

* Implementa√ß√£o de **RAG (Retrieval-Augmented Generation)** para ligar o modelo a guidelines cl√≠nicas oficiais e atualizadas.
* Valida√ß√£o cl√≠nica rigorosa das respostas.
* Integra√ß√£o em plataformas m√≥veis.

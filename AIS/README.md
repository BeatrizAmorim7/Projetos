# ü§∞ Assistente Virtual de Aconselhamento Pr√©-Natal (IA)

**Unidade Curricular:** Ambientes Inteligentes para a Sa√∫de (AIS)

**Mestrado em Engenharia Biom√©dica | Inform√°tica M√©dica**

**Universidade do Minho** - 2024/2025


## Sobre o Projeto

Este reposit√≥rio re√∫ne a documenta√ß√£o e a an√°lise do desenvolvimento de um assistente virtual baseado em LLMs (_Large Language Models_), concebido para prestar informa√ß√£o e apoio ao longo da gravidez. O projeto recorre √† _framework_ **Ollama** para a compara√ß√£o do desempenho de diferentes modelos na resposta a quest√µes relacionadas com o desenvolvimento fetal, nutri√ß√£o e cuidados pr√©-natais.

O objetivo do projeto foi desenvolver um assistente capaz de disponibilizar informa√ß√£o r√°pida, acess√≠vel e cientificamente fundamentada, funcionando como um complemento, e n√£o um substituto, do acompanhamento m√©dico convencional.

O trabalho centrou-se sobretudo no _fine-tuning_ de par√¢metros atrav√©s de _Modelfile_ e na engenharia de _prompts_, de forma a garantir respostas clinicamente rigorosas, seguras e transmitidas com empatia.

## Objetivos

* Desenvolver um assistente virtual focado no contexto cl√≠nico pr√©-natal.
* Comparar o comportamento de diferentes LLMs (pequena e m√©dia escala).
* Otimizar as respostas ajustando par√¢metros como `temperature`, `top_k` e `seed`.
* Avaliar a precis√£o cl√≠nica, clareza e empatia das respostas geradas.

## Tecnologias Utilizadas

* **Framework:** [Ollama](https://ollama.com/) (Execu√ß√£o local de LLMs).
* **Interface:** [Open WebUI](https://docs.openwebui.com/) (Intera√ß√£o gr√°fica com os modelos).
* **Engenharia de Prompt:** Defini√ß√£o de *System Prompts* espec√≠ficos para criar uma _persona_ "emp√°tica e baseada em evid√™ncias".

## Modelos Avaliados

Foram testados quatro modelos distintos, escolhidos pelo equil√≠brio entre desempenho e efici√™ncia computacional:

1. **Phi3 (3.8B):** Modelo leve, focado em efici√™ncia.
2. **LLaMA 3.2 (3B):** Modelo da Meta otimizado para instru√ß√µes.
3. **Gemma-3 (4B):** Modelo aberto da Google.
4. **Mistral (7B):** Modelo conhecido pela fluidez comunicativa.

## Configura√ß√£o e Par√¢metros

A personaliza√ß√£o foi feita atrav√©s do **Modelfile** do _Ollama_, atrav√©s do ajuste das seguintes vari√°veis para controlar a criatividade e consist√™ncia:

* **Temperature:** Variou entre 0.3 e 0.5 (Controlo de aleatoriedade).
* **Top_k:** Variou entre 30 e 45 (Sele√ß√£o de _tokens_ prov√°veis).
* **Seed:** Fixada em 35 para reprodutibilidade.
* **System Prompt:** Instru√ß√µes diretas e restritas para manter um tom emp√°tico, evitar diagn√≥sticos m√©dicos e n√£o usar adjetivos subjetivos exagerados (ex: "wonderful", "amazing").

## Resultados e Conclus√µes

Os modelos foram submetidos a um conjunto de 8 perguntas-chave e 3 cen√°rios cl√≠nicos complexos.

| Modelo | Avalia√ß√£o Geral |
| --- | --- |
| **Phi3** | **Fraco.** Apresentou v√°rias imprecis√µes t√©cnicas (alucina√ß√µes sobre marcos gestacionais). |
| **LLaMA** | **M√©dio.** Boa estrutura, mas propenso a erros graves com temperaturas mais altas (ex: sugeriu alimentos inseguros). |
| **Mistral** | **Bom.** Excelente capacidade comunicativa e educativa, mas por vezes superficial tecnicamente. |
| **Gemma** | **Excelente (Vencedor).** Foi o modelo mais equilibrado. Combinou rigor t√©cnico, clareza e o n√≠vel certo de empatia ("Your little one"). |

**Conclus√£o Principal:**
O modelo **Gemma** destacou-se como a melhor op√ß√£o para este dom√≠nio. Contudo, o trabalho evidenciou que LLMs gen√©ricos, sem acesso a bases de conhecimento externas (RAG), t√™m limita√ß√µes em casos cl√≠nicos complexos e necessitam de supervis√£o humana.

## Trabalho Futuro

* Implementa√ß√£o de **RAG (Retrieval-Augmented Generation)** para ligar o modelo a guidelines cl√≠nicas oficiais e atualizadas.
* Valida√ß√£o cl√≠nica rigorosa das respostas.
* Integra√ß√£o em plataformas m√≥veis.
